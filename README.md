# Лабораторная работа №3

## 1. С использованием техники обучения Transfer Learning обучить нейронную сеть EfficientNet-B0 (предварительно обученную на базе изображений imagenet) для решения задачи классификации изображений Food-101 с использованием фиксированных темпов обучения 0.01, 0.001, 0.0001

### Графики обучения:
- Красный - темп 0.01 на обучении / Голубой - темп 0.01 на валидации
- Оранжевый - темп 0.001 на обучении / Синий - темп 0.001 на валидации
- Розовый - темп 0.0001 на обучении / Зеленый - темп 0.0001 на валидации

*График точности*
![Alt-текст](https://github.com/the-GriS/CNN-food-101/blob/lab_3/diagrams/lab_3/epoch_categorical_accuracy.svg)

*График потерь*
![Alt-текст](https://github.com/the-GriS/CNN-food-101/blob/lab_3/diagrams/lab_3/epoch_loss.svg)

## 2. Реализовать и применить в обучении Косинусное затухание (Cosine Decay), а также определить оптимальные параметры для данной политики

### Графики обучения:
- Розовый - темп 0.01 на обучении / Зеленый - темп 0.01 на валидации
- Красный - темп 0.001 на обучении / Голубой - темп 0.001 на валидации
- Оранжевый - темп 0.0001 на обучении / Синий - темп 0.0001 на валидации

*График точности*
![Alt-текст](https://github.com/the-GriS/CNN-food-101/blob/lab_3/diagrams/lab_3/epoch_categorical_accuracy_cos.svg)

*График потерь*
![Alt-текст](https://github.com/the-GriS/CNN-food-101/blob/lab_3/diagrams/lab_3/epoch_loss_cos.svg)

## 3. Реализовать и применить в обучении Косинусное затухание с перезапусками (Cosine Decay with Restarts), а также определить оптимальные параметры для данной политики

### Графики обучения:
- Розовый - темп 0.01 на обучении / Зеленый - темп 0.01 на валидации
- Красный - темп 0.001 на обучении / Голубой - темп 0.001 на валидации
- Оранжевый - темп 0.0001 на обучении / Синий - темп 0.0001 на валидации

*График точности*
![Alt-текст](https://github.com/the-GriS/CNN-food-101/blob/lab_3/diagrams/lab_3/epoch_categorical_accuracy_cos_res.svg)

*График потерь*
![Alt-текст](https://github.com/the-GriS/CNN-food-101/blob/lab_3/diagrams/lab_3/epoch_loss_cos_res.svg)

## Анализ результатов
При обучении нейроной сети с использованием техники обучения Transfer Learning точность получилась значительно выше(0,6476 при валидации и 0,8377 при обучении), чем при обучении со случайным начальным приближением(0,02184 при валидации и 0,01553 при обучении). Использование техники обучения Transfer Learning лучше на 0,62576% при валидации и на 0,82217% при обучении. Из этого мы делаем вывод, что обучение с использование  Transfer Learning эффективнее нежели метод со случайным начальным приближением. Также время затраченное на обучение Transfer Learning меньше, чем для аналогичной операции для метода случайного начального приближения: 1.2 часа против 6 часов соответственно.
